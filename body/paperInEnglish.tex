% !Mode:: "TeX:UTF-8"
% !Mode:: "TeX:UTF-8"


\charpter{附录}
\section*{附录A~外文资料}

\par{The backpropagation algorithm (Rumelhart, Hinton, \& Williams, 1986) trains the units in the intermediate layers of a feedforward neural net to represent features of the input vector that are useful for predicting the desired output. This is achieved by propagating information about the discrepancy between the actual output and the desired output backward through the net to compute how to change the connection weights in a direction that reduces the discrepancy.In this article we show how to use backpropagation to learn features and constraints when each input vector is not accompanied by a supervision signal that specifies the desired output.}
\par{
When no desired output is specified, it is not immediately obvious what the goal of learning should be. We assume here that the aim is to characterize the observed data in terms of many different features and constraints that can be interpreted as hidden factors. These hidden factors could be used for subsequent decision making or they could be used to detect highly improbable data vectors by using the global energy.We define the probability that the network as signs to a data vector$x$,  , by comparing its global energy$E(x)$,  , with the energies of all possible data vectors,  :
\begin{equation}\label{equation1}p(x) = \frac{{{e^{ - E(x)}}}}{{\sum\nolimits_v {{e^{ - E(v)}}} }}\end{equation}
}
\par{
Intuitively, a good unsupervised learning procedure should find hidden factors that assign high probability to patterns that typically occur. This can be achieved by lowering the energies of observed data vectors and raising the energies of “negative” data vectors—patterns that should be observed if the hidden factors constituted a good model of the data. By using the current model to generate a set of negative data vectors we can convert an unsupervised learning task into the supervised task of assigning low energies to the observed data vectors and high energies to the negative data vectors. Notice, however, that the set of negative data vectors depends on the current model and it will change as the model learns. }
\par{The quality of the set of features and constraints discovered by the neural network can be quantified by the summed log probability that gets assigned to the observed data vectors. The contribution of a single data vector to this sum is:
\begin{equation}\label{equation2}\log p(x) =  - E(x) - \log \sum\limits_v {{e^{ - E(v)}}} \;\;\;\end{equation}
}
\par{The features and constraints can be improved by repeatedly adjusting the weights on the connections to maximize the log probability of the observed data. To perform gradient ascent in the log likelihood we would need to compute exact derivatives of the log probabilities:
 \begin{equation}\label{equation3}\Delta {w_{ij}}{\kern 1pt} {\kern 1pt} {\kern 1pt}  \propto {\kern 1pt} {\kern 1pt} \frac{{\partial \log {\kern 1pt} p(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}} = {\kern 1pt}  - \frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}{\kern 1pt}  + {\kern 1pt} {\kern 1pt} \sum\nolimits_v {p(v)\frac{{\partial E(v){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}} \;\end{equation}
where ${{\rm{w}}_{{\rm{ij}}}}$ is the weight on the connection from unit $i$ in one layer to unit $j$ in the next layer.
}
\par{The first term is easy to compute.We assume that each unit, $j$, sums the weighted activities coming from units, $i$, in the layer below to get its total input,${z_j} = {\kern 1pt} {\kern 1pt} \sum\nolimits_i {{y_i}{w_{ij}}} $  , where an activity ${y_i}$ in the layer below is equal to  ${x_i}$ if it is the input layer. A smooth nonlinear function ${z_j}$ of  is then used to compute the unit’s activity, ${y_j}$. The energy contributed by the unit can be any smooth function of its activity. In this article we use two layers of nonlinear hidden units and the energy is determined by the activities of units in the second hidden layer:
\begin{equation}\label{equation4}E(x)\; = \;\sum\limits_j {{\lambda _j}\log (1 + y_j^2)} \;\end{equation}

}
\par{where  ${y_j}$is the activity of unit $j$ in the second hidden layer and   ${\lambda _j}$is a scale parameter that is also learned by contrastive backpropagation. This “heavy-tailed” energy contribution is good for modeling constraints that are usually satisfied fairly precisely and occasionally violated by a lot. In images of natural scenes, for example, a local, oriented edge filter will have an output of almost exactly zero almost everywhere. On the few occasions when its output departs from zero, however, it may be quite large, so the distribution of the violations is very non-Gaussian.By using the energy contributions in Equation 4 we encourage the network to model the data distribution by finding constraints of this type (Hinton \& Teh, 2001).
}
\par{After performing a forward pass through the network to compute the activities of all the units, we do a backward pass as described in Rumelhart et al. (1986). The backward pass uses the chain rule to compute $\frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}$ for every connection weight, and by backpropagating all theway to the inputs we can also compute $\frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {x_i}}}$  for each component,${x_i}$  , of the input vector.
}
\par{Unfortunately, the second term in Equation \ref{equation3} is much harder to deal with. It involves a weighted average of the derivatives from all conceivable data vectors so it cannot be computed efficiently except in special cases.We usually expect, however, that this average will be dominated by a very small fraction of the conceivable data vectors, so it seems reasonable to approximate this term by averaging  $\frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}$ over a relatively small number of samples from the distribution $p\left( . \right)$ .One way to generate samples from this distribution is to run a Markov chain that simulates a physical process with thermal noise. If we think of the dataspace as forming a horizontal plane and we represent the energy of each data vector as height, the neural network defines a potential energy surface with a height and gradient that are easy to compute.We imagine a particle on this surface that tends to move downhill but is also jittered by additional Gaussian noise. After enough steps, the particle will have lost all information about where it started and if we use small enough steps, its probability of being at any particular point in the dataspace will be given by the Boltzmann distribution in Equation 1. This is a painfully slow way of generating samples and even if the equilibrium distribution is reached, the variance created by sampling may mask the true learning signal.
}
\par{Rather surprisingly, it is unnecessary to allow the simulated physical process to reach the equilibrium distribution. If we start the process at an observed data vector and just run it for a few steps, we can generate a “confabulation” that works very well for adjusting the weights (Hinton, 2002). Intuitively, if the Markov chain starts to diverge from the data in a systematic way, we already have evidence that the model is imperfect and that it can be improved (in this local region of the dataspace) by reducing the energy of the initial data vector and raising the energy of the confabulation. It is theoretically possible that this learning procedure will cause the model to assign very low energies to unvisited regions of the dataspace that are far from anydata vector. However, the fact that the learning works well on a variety of tasks suggests that this theoretical problem is insufficient grounds for rejecting the learning procedure, just as the existence of local minima was insufficient grounds for rejecting backpropagation.
}
\par{The contrastive backpropagation learning procedure cycles through the observed data vectors adjusting each weight by:
 \begin{equation}\label{equation5}\Delta {w_{ij}} = \eta \;\left( { - \frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}{\kern 1pt}  + {\kern 1pt} {\kern 1pt} \frac{{\partial E(\mathop x\limits^ \wedge  ){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}} \right){\kern 1pt} \;\;\end{equation}
where $\eta$ is a learning rate and   $\mathop x\limits^ \wedge $is a confabulation produced by starting at $x$  and noisily following the gradient of the energy surface for a few steps.
}
\par{To illustrate the learning procedure, we applied it to the task of discovering the nonlinear kinematic constraints in a simulated three-dimensional “arm” that has five rigid links and five ball joints. The first ball joint attaches the arm to the origin, and each data vector consists of the 15 cartesian coordinates of the remaining link endpoints. This apparently 15-dimensional data really has only 10 degrees of freedom because of the 5 one-dimensional constraints imposed by the 5 rigid links. These constraints are of the form:
 \begin{equation}\label{equation6}
{\left( {{x_i} - {x_{i + 1}}} \right)^2} + {\left( {{y_i} - {y_{i + 1}}} \right)^2} + {\left( {{z_i} - {z_{i + 1}}} \right)^2} - {l_{i,i + 1}}^2 = 0\;\;
 \end{equation}
where $i$ and$i + 1$   index neighboring joints and  ${l_{i,i + 1}}$ is the length of the link between them. Because the constraints are highly nonlinear, linear dimensionality-reduction methods like principal components analysis or factor analysis are of little help.
}
\par{We used a neural net with 15 input units and two hidden layers. Each of the 15 units in the first hidden layer computes aweighted sum of the inputs and then squares it. Each of the 5 units in the top layer computes a weighted sum of the squares provided by the first hidden layer and adds a learned bias. It is clear that with the right weights and biases, each top-layer unit could implement one of the constraints represented by Equation 6 by producing an output of exactly zero if and only if the constraint is satisfied. The question is whether the network can discover the appropriate weights and biases just by observing the data.
}
\par{For this example, the units in the first hidden layer do not contribute to the energy and the units in the second hidden layer each contribute an energy of ${\lambda _j}\log (1 + y_j^2)$ . This heavy-tailed energy function penalizes top-level units with nonzero outputs, but changing the output has little effect on the penalty if the output is already large.
}
\par{Fig. 1 shows the weights and top-level biases that were learned by contrastive backpropagation.For each pair of neighboring joints, there are three units in the first hidden layer that have learned to compute differences between the coordinates of the two joints. These differences are always computed in three orthogonal directions. Each unit in the second hidden layer has learned a linear combination of the five constraints, but it uses weights of exactly the same size for the three squared differences in each constraint so that it can exactly cancel the fixed sum of these three squared differences by using its bias.
}
\par{The same network can also learn the five constraints when a random 10\% of the input variables are missing from each data vector. The missing input variables are treated as additional parameters that are initialized at random values and are learned using a version of Equation \ref{equation5} in which ${w_{ij}}$  is replaced by${x_i}$  . The random inputs mean that each instance of a constraint is only satisfied with a probability of ${.9^6} = 0.53$  at the start of learning. However, the heavy-tailed energy function means that strongly violated constraints only contribute a very small gradient, so the learning is driven by the accurately satisfied constraints.
}
\par{We have also applied a similar neural network on the more challenging task of learning features that allow us to compactly describe the statistical structure within small patches of digitized images of natural scenes. For this task, we used the same layered architecture, activation functions, and energy functions as described previously, but this time in a net with 256 units in the input layer and 400 units in each of the two hidden layers.We also arranged the units within each hidden layer on a $20 \times 20 $square grid, and topographically restricted the connectivity so that each unit in the first hidden layer could only send connections to the unit at the same grid position in the second hidden layer and to this unit’s 24 nearest neighbors.
}\par{Fig.\ref{fig:deeplearning} illustrates some of the features learned in such a model. The first-layer units have self-organized to form a representation of the image patches in terms of a set of oriented, band-pass features. These features bear a striking resemblance to the receptive fields of simple
\begin{figure}[htbp]
\centering
\includegraphics[width=0.4\textwidth]{deeplearning.eps}
\label{fig:deeplearning}
\vspace{\baselineskip} % 表示图与正文空一行
\end{figure}
\par{
\footnotesize
 The areas of the small black and white rectangles represent the magnitudes of the negative and positive weights learned by the network. Each column in the lower block represents the weights on the connections to a unit in the first hidden layer from the joint coordinates ${x_1},{\rm{ }}{y_1},{\rm{ }}{z_1},{\rm{ }}{x_2},{\rm{ }}{y_2},{\rm{ }}{z_2} \ldots {x_5},{\rm{ }}{y_5},{\rm{ }}{z_5}$  . For example, the first, second, and seventh columns show the weights of three hidden units that compute the squared distances between the last two joints in three orthogonal directions. Each row in the higher block represents the weights on connections from units in the first hidden layer to a unit in the second hidden layer. For example, the first, second, and seventh units in the first hidden layer have equal negative weights to the unit represented by the third row in the higher block. The weights started with very small random values and were learned by 3,300 passes through a training set of 800 random arm configurations in which every link was of length 1. The weights were updated after every 100 training cases. To eliminate unnecessary weights, a decay toward zero of 0.0002 was added to the weight change,   $\Delta {w_{ij}}$specified by Equation 5 before multiplying by the learning rate for that connection, ${\eta _{ij}}$ , which started at 0.0001. ${\eta _{ij}}$ increased by 1\% if  $\Delta {w_{ij}}$ agreed in sign with its previous value and decreased by 5\% if it disagreed. To further speed learning without causing divergent oscillations, each weight update included 0.9 times the previous weight update.}

cells found in the primary visual cortex of most mammals and are also similar to the features learned in other models that seek to capture statistical structure in natural images (Bell \& Sejnowski, 1997; Olshausen \& Field, 1996). The second-layer units display similar response preferences for orientation and spatial frequency, but appear to be somewhat insensitive to the spatial phase present in the input. As a result of the restricted connectivity between the two hidden layers, the features form a topographic map with local continuity in spatial location, orientation, and spatial frequency.}


\section {附录B~中文译文}
\setcounter{equation}{0}
\par{反向传播算法（(Rumelhart, Hinton, \& Williams, 1986）中对具有前反馈功能的神经网络中间层进行训练对于得到与输出想要结果相对应的输入向量来说是十分有用的。这种算法采用传播真实的输出和想要的输出之间的差异来计算某一个方向的权值的变化以便于去减少这种差异。在这篇文章里面，我们将介绍一种如何用反向传播的技术来学习那些没有被监督信号标记的输入向量的特征和约束。}
\par{如果所需的输出结果不明确，那么很显然机器不能够很明确的知道学习的目标是什么。我们在这里假定，学习的目标是在所观察到的数据中学习一些不同特征和约束也即是隐藏因子。这些隐藏因子可以用于随后的决策或者用高能量来表述的极不可能出现的数据载体。在这种网络中，对于输入向量$x$ 的可能性可以采用向量 的全局能量$E(x)$ 与所有可能输入向量$v$ 的能量的比值来表示。
\begin{equation}\label{equation1}p(x) = \frac{{{e^{ - E(x)}}}}{{\sum\nolimits_v {{e^{ - E(v)}}} }}\end{equation}
}

\par{直观地说，一个良好的无监督学习过程应该发现概率很高而且经常出现的隐性因素。这可以通过降低所观察到的数据向量的能量、提高的“负”的数据载体实现。这也就是能够发现可以用来构造好的数据模型的隐藏因子的模式。通过使用当前模型来生成一组负的数据向量，我们可以把无监督的学习任务转换为一种给观察数据赋予低能量而负数据的赋予高能量的监督学习过程。然而，要注意的是负数据向量要取决于当前的模型，它会随着模型的学习过程而有所改变。}
\par{
神经网络发现的特征和约束的质量可以用观察的数据的概率的对数和表示。对于单个向量的其对于整个和的贡献是：
\begin{equation}\label{equation2}\log p(x) =  - E(x) - \log \sum\limits_v {{e^{ - E(v)}}} \;\;\;\end{equation}
}

\par{这些特征和约束可以通过不断地调整不同神经元之间联系的权重来进行提升，以便于最大化观察数据的概率的对数。我们可以通过计算概率对数来表示相似度对数的梯度。
 \begin{equation}\label{equation3}\Delta {w_{ij}}{\kern 1pt} {\kern 1pt} {\kern 1pt}  \propto {\kern 1pt} {\kern 1pt} \frac{{\partial \log {\kern 1pt} p(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}} = {\kern 1pt}  - \frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}{\kern 1pt}  + {\kern 1pt} {\kern 1pt} \sum\nolimits_v {p(v)\frac{{\partial E(v){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}} \;\end{equation}
其中 ${{\rm{w}}_{{\rm{ij}}}}$ 是第 $i$ 层神经元到$j$  层神经元之间联系的权重。}
	\par{第一项很容易计算。我们假设对于每一个神经元 $j$对来自其下一层的神经元$i$ 进行加权求和得到总输出为${z_j} = {\kern 1pt} {\kern 1pt} \sum\nolimits_i {{y_i}{w_{ij}}} $ ，其中如果${y_i}$ 是输入层的话,那么${x_i}$ 和${y_i}$ 相等。平滑非线性函数 ${z_j}$用于计算这个神经元${y_j}$ 的活动量。每一个神经元的能量可以用任意平滑函数来表示。在这篇文章里，我们用两层非线性隐藏神经元，而且能量由第二个隐藏层决定的计算由公式(\ref{equation4})表示。
 \begin{equation}\label{equation4}E(x)\; = \;\sum\limits_j {{\lambda _j}\log (1 + y_j^2)} \;\end{equation}
在这里 ${y_j}$是神经元$j$在第二个隐藏层的活动量， ${\lambda _j}$是通过对比反向传播方法学习到的尺度参数。这种“重尾”的能力计算对于构造恰当的约束来说是有益处的。在自然风景的图像中，比如说一个本地面向边缘的滤波器会得到一个几乎所有的点都是0 的输出。很少会出现输出偏离0的情况，但是，这个也许会功能很强大，所以这种侵犯分布是非常non-Gaussian的。通过用等式4中的能量计算，我们希望这个网络能够找到一种类型的约束来对数据分布进行建模。}
\par{通过网络进行直传来计算所有单位的活动量之后，我们做一个由Rumelhart在1986 年提出的后向传播的实验。后向传播使用链式法则来计算对于每一个连接的权重 $\frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}$ ，通过一路反向传播直到结束，对于输入向量每一个分量 ${x_i}$我们可以计算出$\frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {x_i}}}$ 。}
\par{不幸的是，公式\ref{equation3}中的第二个式子比较难于处理。它涉及到从所有可能的数据向量的导数的加权平均值，因此除了一些特殊情况以外，它不能有效地计算出来。然而我们通常希望这个平均值由每一个可以感知得到的小的分量确定，所以通过在相当小数量的数据样本上来计算 $\frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}$的平均值来估计其分布$p\left( . \right)$  似乎是合理的。一种方法是运行一个具有热噪声的物理过程的马尔可夫链来得到这些样本。如果我们把数据空间看作是是水平面的话，那么我们可以把每一个数据的势能作为高，神经网络通过高和很容易计算的梯度来决定一个潜在的势能面。我们可以想象粒子在该表明沿着下坡方向移动，但是也会由于附加的高斯噪声而抖动。经过一定的步数之后，分子会丢失来自开始地方的所有信息。如果我们使用足够小的步间隔，它在数据空间中所有可能出现的地方服从Boltzmann分布。这种构造样本的过程缓慢而又痛苦，而且即使最后得到需要的分布，由抽样产生的差异也有可能会掩盖真正的学习信号。}
\par{相当令人惊讶地是，模拟的物理过程达到平衡分布的条件是不必要的。如果我们在观测数据向量上开始这个过程，只要运行几步，我们就可以生成可以很好地调节权重的一个“虚构样本”（Hinton, 2002).） 。直观地说，如果该马尔科夫链以一个系统的方式将数据发散，现在已经有证据表明，该模型是不完美的，并且它可以通过降低初始数据矢量的能量和提高虚构的能量来改善（在数据空间的这个局部区域）。这在理论上是可行的，因为这个学习过程会导致模型给那些远离任何数据的向量所在的未访问的数据空间区域以低能量。然而，这种学习方法在大量的数据上运行良好的事实表明，这个理论不足于拒绝学习这个学习过程，就如同局部极小的存在使得不能够拒绝反向传播。}
\par{对比反向传播学习过程周期通过对以下公式对观察到的数据的权重进行调整：  \begin{equation}\label{equation5}\Delta {w_{ij}} = \eta \;\left( { - \frac{{\partial E(x){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}{\kern 1pt}  + {\kern 1pt} {\kern 1pt} \frac{{\partial E(\mathop x\limits^ \wedge  ){\kern 1pt} {\kern 1pt} {\kern 1pt} }}{{\partial {w_{ij}}}}} \right){\kern 1pt} \;\;\end{equation}
其中$\eta$ 是学习速率而 $\mathop x\limits^ \wedge $ 是由其实向量$x$ 得到的虚构向量。势能面的梯度通过噪声的形式来影响 。}
	\par{为了更好地阐述这个学习过程，我们在把它应用在一个模拟的具有五个刚性连接和五个球状的关节的三维手臂以用于探索非线性的运动约束。第一个球状关节连接到手臂的原始部分，每一个数据向量包括15个用于保留链接点的笛卡尔坐标。很显然这些15维的坐标只有10维的自由度因为其中的5维由5个关节点连接构成。这些约束的格式如\ref{equation6}：
 \begin{equation}\label{equation6}
{\left( {{x_i} - {x_{i + 1}}} \right)^2} + {\left( {{y_i} - {y_{i + 1}}} \right)^2} + {\left( {{z_i} - {z_{i + 1}}} \right)^2} - {l_{i,i + 1}}^2 = 0\;\;
 \end{equation}

其中 $i$$i + 1$ 和 是邻接节点的索引，而 ${l_{i,i + 1}}$是两个连接之间的长度，由于这些约束是高度非线性的，所以线性维度的降维过程类似于主成分分析，而不是因子分析。}
\par{我们采用了一个具有15个神经元和两个隐藏层的神经网络。第一个隐藏层计算输入向量的加权平均值的平方。顶层中五个单元每一个计算前述的平方的权重和并且与学习偏差相加。很显然如果具有正确的权重和偏差，每一个层都可以实现公式6中当且仅当约束完全满足，输出结果为0的约束.问题是仅仅通过观察数据能否得到恰当的权值和偏差。}
\par{在这个例子中，第一个隐藏层不贡献能量，第二个隐藏层以 ${\lambda _j}\log (1 + y_j^2)$贡献能量。这重尾的函数采用非零输出结果惩罚顶层单元，但是如若输出已经很大，改变输出对这种惩罚鲜有影响。}
\par{图1显示了由对比反向传播算法学习得到的权重和顶层偏差。对于每一个邻近的连接点，第一个隐藏层中有三个神经元来学习计算两节点坐标间的差异。这些差异经常在三个正交方向上计算。在第二隐层中的每个单元学习了五个约束的线性组合，但它使用的权重与每个约束的三次微分同阶，由此它可以通过使用其偏差确切的消去三次微分的定和。}
\par{当每个数据向量中随机百分之十的输入变量缺失同样的网络也可以学习五个约束。缺失的输入变量可作为额外参数，初始化为随机值，由公式\ref{equation5}所示的模式学习，${w_{ij}}$ 替换为${x_i}$ 。这些随机输入意味着每个实例的约束在学习起初只有的 ${.9^6} = 0.53$ 概率满足。但是，重尾能量函数意味着强烈违反约束仅仅会贡献很小的梯度，即是说学习过程会被精确满足约束所驱使。}
\par{我们同样在对学习更具挑战性的任务上应用相似的神经网络，其允许我们简洁的描述小片自然风光数字图像的序列统计结构。在此任务上，我们用如前所述的同样的网络层结构，激活函数和能量函数，不同的是此网络在输入层具有256个单元，在两个隐层的每层都有400单元。我们同样在每个隐层中排列这些单元在$20 \times 20 $的方格上，并在图形上限制了其连通性，以使得第一隐层每个单元仅可以连接第二隐层同样网格位置的单元和其24近邻。
\begin{figure}[htbp]
\centering
\includegraphics[width=0.4\textwidth]{deeplearning.eps}
\label{fig:deeplearning}
\vspace{\baselineskip} % 表示图与正文空一行
\end{figure}}
\par{
\footnotesize
 Fig.\ref{fig:deeplearning}，矩形的白点和黑点代表通过网络学习到的正负权重的值。每一列的下部分表示从${x_1},{\rm{ }}{y_1},{\rm{ }}{z_1},{\rm{ }}{x_2},{\rm{ }}{y_2},{\rm{ }}{z_2} \ldots {x_5},{\rm{ }}{y_5},{\rm{ }}{z_5}$ 连接点学习到的连接权值。比如说，在第一、第二、第七列中展示了可以用于计算两个连接点之间的三维正交距离平方的神经元的权重。在每一行的上部分表示从第一个隐藏层到第二个隐藏层之间的权重。比如说第一个隐藏层的第一个、第二个、第七个单元中和第三行的神经元具有相同的负权重。这些权重以一些非常小的随机值开始，并3300次通过800个随机胳膊构成的连接长度为1 的训练集。每训练100 次，权重更新一次。为了消除不必要的权重，每一加上了朝着权重变化方向加了0.0002的衰减. 在乘上学习比例 ${\eta _{ij}}$(以0.0001为起始值)之前， $\Delta {w_{ij}}$由公式(\ref{equation5}) 来确定。如果 $\Delta {w_{ij}}$和它先前的值的信号相符合那么 ${\eta _{ij}}$以1\% 的速度增加，否则以5\% 的速度减少。为了进一步加快学习，而不会造成发散振荡，各权重的更新是其上一次更新速度的0.9 倍。}

\par{图二展示了用这个模型学习到的一些特征。第一层的神经元自己学习一个具有连通性、定向性的新的图像片段特征。这些特征有着和在大多数哺乳动物的初级视觉层次中发现的简单感知细胞有着惊人相似度和自然图像中的统计结构特征也十分相似(Bell \&Sejnowski, 1997; Olshausen \& Field, 1996)。 第二层的神经元展现显示类似的反应偏好和空间频率。但是似乎对于输入层的空间相位不敏感。由于两个隐藏层之间的严格限制，方向局部连续性的地形图和空间频率构成了一个新的特征。}



